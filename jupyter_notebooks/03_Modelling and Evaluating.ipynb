{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **03_Modelling and Evaluating**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "**Provide ability to answer business requirement 2**\n",
        "\n",
        "* The client is interested in predicting if a cherry leaf is healthy or contains powdery mildew.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/dataset/cherry_leaves_dataset/cherry-leaves/test\n",
        "* inputs/dataset/cherry_leaves_dataset/cherry-leaves/train\n",
        "* inputs/dataset/cherry_leaves_dataset/cherry-leaves/validation\n",
        "* image shape embeddings\n",
        "\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* create ability to answer for Business Requirements 2\n",
        "* create plot for image distribution in train, validation, and test set\n",
        "* Image augmentation\n",
        "* Class indices to change prediction inference in labels\n",
        "* Machine learning model creation and training\n",
        "* Save the model\n",
        "* Learning curve plot for model performance\n",
        "* Model evaluation on pickle file\n",
        "* Prediction on the random image file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Set Data Directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import libraries and model packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Model packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "Change the working directory from its current folder to its parent folder\n",
        "> access the current directory with ```os.getcwd()```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "Make the parent of the current directory the new current directory\n",
        "> ```os.path.dirname()``` gets the parent directory; ```os.chir()``` defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set input directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set train, validation an test paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data_dir = 'inputs/dataset/cherry_leaves_dataset/cherry-leaves'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
        "    print('Old version is already available create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set label names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_path)\n",
        "print('Label for the images are', labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import saved image shape embedding\n",
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Count numbers of images in train, test and validation data and display them in a chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Bar Chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we count the number of images in each label, show and save them in a bar chart.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# code for Data Visualization and its functions were adapted and taken from Walkthrough Project 01 Malaria Detector \n",
        "\n",
        "# Create an empty dictionary\n",
        "data_dict = {\n",
        "    'Set': [],\n",
        "    'Label': [],\n",
        "    'Frequency': []\n",
        "}\n",
        "\n",
        "# Define the number of rows you want to create\n",
        "image_folders = ['train', 'validation', 'test']\n",
        "\n",
        "# Loop to dynamically create and append rows to the dictionary\n",
        "for image_folder in image_folders:\n",
        "    for label in labels:\n",
        "        row = {\n",
        "            'Set': image_folder,\n",
        "            'Label': label,\n",
        "            'Frequency': int(len(os.listdir(my_data_dir + '/' + image_folder + '/' + label)))  \n",
        "        }\n",
        "        for key, value in row.items():\n",
        "            data_dict[key].append(value)\n",
        "        print(\n",
        "            f\"* {image_folder} - {label}: {len(os.listdir(my_data_dir+'/'+ image_folder + '/' + label))} images\")\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "df_freq = pd.DataFrame(data_dict)\n",
        "\n",
        "print(\"\\n\")\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label', palette='pastel')\n",
        "plt.savefig(f'{file_path}/labels_distribution.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pie Chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again we count the number of images in each label to check if the next part of code uses the correct data, show and save them in a pie chart.\n",
        "\n",
        "Unlike the previous bar chart this pie chart only shows the total image distributioj between train-, validation- and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# looked up other students projects to be able to subdivide each set\n",
        "# into healthy and mildew infected parts, nothing so far & everything else I tried was buggy\n",
        "\n",
        "image_folders = ['train', 'validation', 'test']\n",
        "data_list=[]\n",
        "for image_folder in image_folders:\n",
        "    for label in labels:\n",
        "        n=int(len(os.listdir(my_data_dir + '/' + image_folder + '/' + label)))\n",
        "        n+=n\n",
        "        print(\n",
        "            f\"* {image_folder} - {label}: {len(os.listdir(my_data_dir+'/'+ image_folder + '/' + label))} images\")\n",
        "    data_list.append(n)\n",
        "\n",
        "\n",
        "px = 1/plt.rcParams['figure.dpi'] \n",
        "plt.subplots(figsize=(12,6))\n",
        "plt.pie(data_list, labels = image_folders, colors = plt.cm.Pastel2.colors, autopct='%.1f%%')\n",
        "plt.title(f'Leaves dataset image distribution\\n')\n",
        "plt.savefig(f'{file_path}/image_distribution_piechart.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we require more data for our deep learning models, we inrease the number of randomized images. That is why we use image augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the ```ImageDataGenerator ``` funtion whih generates batches of image data.\n",
        "\n",
        "These images are generated from our already existing data, by:\n",
        "* rotating imagges by 20 degree\n",
        "* shifting the width and height of the images by a 0.1 ratio\n",
        "* shearing the image by 0.1\n",
        "* zooming into the image by 10%\n",
        "* flipping the image\n",
        "* fillig broken pixels\n",
        "\n",
        "This is saved in the variable ```augmented_image_data ```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# code for Data Visualization and its functions were adapted and taken from Walkthrough Project 01 Malaria Detector \n",
        "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
        "                                          width_shift_range=0.10,\n",
        "                                          height_shift_range=0.10,\n",
        "                                          shear_range=0.1,\n",
        "                                          zoom_range=0.1,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=True,\n",
        "                                          fill_mode='nearest',\n",
        "                                          rescale=1./255\n",
        "                                          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Augment training image dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set the batch size and augment our training data set.\n",
        "\n",
        "We get data directly from the training dataset through the ```flow_from_directory ``` and transform every single data piece/image. Each image is transformed with the ```image_shape``` variable, the RGB colour mode, the batch size, which is set to 20, the binary class mode, whih is used since we have two labels, hence two classes and then shuffled randomly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# code for Data Visualization and its functions were adapted and taken from Walkthrough Project 01 Malaria Detector \n",
        "batch_size = 20  # this sets the batch size\n",
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     shuffle=True\n",
        "                                                     )\n",
        "\n",
        "train_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We do the same with the validation and test data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Augment validation image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='categorical',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "validation_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Augment test image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='categorical',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "\n",
        "test_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The class indices are the same for all datasets. ```0``` for healthy leaes & ```1``` for mildew infeted leaves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot augmented training image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we plot the augmented images. We startg with plotting the augmented training images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(4):\n",
        "    img, label = next(train_set)\n",
        "    print(img.shape)  \n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expeted the images look transformed compared to the image montage from our previous notebook. This meand our transformation and hence augmentation was succesfull.\n",
        "\n",
        "We do the same for the validation and test datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot augmented validation images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(4):\n",
        "    img, label = next(validation_set)\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot augmented test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(4):\n",
        "    img, label = next(test_set)\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All images were successfully augmented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save class indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We save the class indices for both labels to be used later on in the output folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model we create should learn from the dominant feature of our labelled images, in our case the diminant feature is thew whitish powder on the green leaves which is there because they are mildew infected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Machine Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a model by defining the function ```create_tf_model```.\n",
        "\n",
        "Our model has five layers:\n",
        "* convolution - seleccts the dominant pixel value from the non-dominant pixels\n",
        "* max-pooling - reduces the size of the image which contains the dominant feature\n",
        "* flatten - flattens matrix into a list of values (vector)\n",
        "* dense - gives the output\n",
        "* dropout - avoids overfitting\n",
        "\n",
        "We set the compiler and do a binary classification with the ```softmax``` ffunction\n",
        "\n",
        "These layers inrease the accuracy and develop a convolution neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# code for Data Visualization and its functions were adapted and taken from Walkthrough Project 01 Malaria Detector \n",
        "def create_tf_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the model summary to understand the numbers of our p√∂arameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_tf_model().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The number of parameters are 7,662,209 (might need to be adapted since it is quite big). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Early stopping stops the model training 'activity' in a case of over- or underfitting.\n",
        "\n",
        "We fit our model and use the ```early_stop``` variable in it.\n",
        "We use 15 epochs and got a callback after the 8th epoch, therefore 8 epochs would be the best. In case we can improve our project this will be redone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_tf_model()\n",
        "model.fit(train_set,\n",
        "          epochs=15,\n",
        "          steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "          validation_data=validation_set,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We save our model to the output folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('outputs/v1/mildew_detection_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "    # create here your folder\n",
        "    # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
